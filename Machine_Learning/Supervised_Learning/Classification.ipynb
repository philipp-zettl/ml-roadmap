{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5Kupl_YwNei"
      },
      "source": [
        "# Classification\n",
        "\n",
        "Classification is the process of predicting the class of given data points. Classes are sometiems called labels, targets or categories.  \n",
        "Classification predictive modeling, short classification, is the task of approximating a mapping function $f$ from input variables $X$ to discrete output variables $y$.\n",
        "\n",
        "An example for a binary classification might be a spam detector for your email service, since there are only 2 classes, spam or no spam, to classify. If we train our classification algorithm right, we're able to classify previously unknown emails correctly.\n",
        "\n",
        "Classification algorithms belongs to the family of supervised learning algoirthms. There are two types of learners in classification\n",
        "\n",
        "## Lazy\n",
        "- store training data\n",
        "- classifies based on most related data\n",
        "- less training time but more time to predict than eager learners\n",
        "- knn, case-based reasoning\n",
        "\n",
        "## Eager\n",
        "- construct classification model based on given training data\n",
        "- requires single hypothesis that covers entire instance space\n",
        "- long time training but little time predicting\n",
        "- Decision Tree, Naive Bayes, Artificial NN\n",
        "\n",
        "# Algorithms\n",
        "As in any field of ML there's **no algorithm that fits all** needs. The decision on the algorithm depends on the application and the nature of the available data set.\n",
        "\n",
        "Starting with eager algorithms.\n",
        "\n",
        "## Logistic Regression\n",
        "- A regression model used for classification\n",
        "- used when the features are categorial\n",
        "\n",
        "### Code\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMA-CQ3jsCHB",
        "outputId": "6782a028-c823-4753-c9a4-8ddd3e8464c7"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "X, y = load_iris(return_X_y=True)\n",
        "X = X[:, :2]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=9)\n",
        "\n",
        "# Create an instance of Logistic Regression Classifier and fit the data.\n",
        "logreg = LogisticRegression(C=1e6)\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "output = logreg.predict(X_test)\n",
        "\n",
        "print(f'Predicted {len(y_test) - sum(np.abs(output-y_test))}/{len(y_test)} right.')\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted 28/30 right.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vg4Q_yuDsCj-"
      },
      "source": [
        "\n",
        "\n",
        "## Decision Tree\n",
        "- builds classifiction or regression models in form of a tree structure\n",
        "- utilizes a set of conditionals which is mutually exclusive and exhaustive for classification\n",
        "- learns sequentially using training data\n",
        "- repeated learning until meeting a terminal condition\n",
        "- top-down recursive divide-and-conquer construction\n",
        "- categorial or discretized attributes\n",
        "- attributes higher in the tree have more impact towards classification\n",
        "- tends to\n",
        "  - overfit and generate too many branches\n",
        "  - reflects anomalies\n",
        "- can be improved by\n",
        "  - pre-pruning\n",
        "  - post-pruning\n",
        "\n",
        "#### Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Uo57OU-06Nr"
      },
      "source": [
        "from sklearn import tree\n",
        "\n",
        "X = [[0, 0], [1, 1]]\n",
        "Y = [0, 1]\n",
        "clf = tree.DecisionTreeClassifier()\n",
        "clf = clf.fit(X, Y)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNLF30up1HAl",
        "outputId": "46cb0516-a2c4-478f-89cd-9b88f59f83dc"
      },
      "source": [
        "clf.predict([[2,2]])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdLVVbzp1Jfm",
        "outputId": "9bcd2774-450e-4881-e4b8-85206add69ae"
      },
      "source": [
        "proba = clf.predict_proba([[2., 2.]])\n",
        "log_proba = clf.predict_log_proba([[2., 2.]])\n",
        "\n",
        "print(proba)\n",
        "print(log_proba)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 1.]]\n",
            "[[-inf   0.]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py:948: RuntimeWarning: divide by zero encountered in log\n",
            "  return np.log(proba)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iI5pGDa1jU6"
      },
      "source": [
        "Now using a more advanced, multiclass example for classification:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTssmyLD1ZTN"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn import tree\n",
        "\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "clf = tree.DecisionTreeClassifier()\n",
        "clf = clf.fit(X, y)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhEL4C4Q19Mg"
      },
      "source": [
        "After a tree is trained, it can be visualized using"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 543
        },
        "id": "jCuZlPAQ11Qh",
        "outputId": "150904ca-e87e-4e4e-8e34-567648addf6f"
      },
      "source": [
        "tree.plot_tree(clf)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(167.4, 199.32, 'X[2] <= 2.45\\ngini = 0.667\\nsamples = 150\\nvalue = [50, 50, 50]'),\n",
              " Text(141.64615384615385, 163.07999999999998, 'gini = 0.0\\nsamples = 50\\nvalue = [50, 0, 0]'),\n",
              " Text(193.15384615384616, 163.07999999999998, 'X[3] <= 1.75\\ngini = 0.5\\nsamples = 100\\nvalue = [0, 50, 50]'),\n",
              " Text(103.01538461538462, 126.83999999999999, 'X[2] <= 4.95\\ngini = 0.168\\nsamples = 54\\nvalue = [0, 49, 5]'),\n",
              " Text(51.50769230769231, 90.6, 'X[3] <= 1.65\\ngini = 0.041\\nsamples = 48\\nvalue = [0, 47, 1]'),\n",
              " Text(25.753846153846155, 54.359999999999985, 'gini = 0.0\\nsamples = 47\\nvalue = [0, 47, 0]'),\n",
              " Text(77.26153846153846, 54.359999999999985, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
              " Text(154.52307692307693, 90.6, 'X[3] <= 1.55\\ngini = 0.444\\nsamples = 6\\nvalue = [0, 2, 4]'),\n",
              " Text(128.76923076923077, 54.359999999999985, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 0, 3]'),\n",
              " Text(180.27692307692308, 54.359999999999985, 'X[2] <= 5.45\\ngini = 0.444\\nsamples = 3\\nvalue = [0, 2, 1]'),\n",
              " Text(154.52307692307693, 18.119999999999976, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 2, 0]'),\n",
              " Text(206.03076923076924, 18.119999999999976, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 0, 1]'),\n",
              " Text(283.2923076923077, 126.83999999999999, 'X[2] <= 4.85\\ngini = 0.043\\nsamples = 46\\nvalue = [0, 1, 45]'),\n",
              " Text(257.53846153846155, 90.6, 'X[0] <= 5.95\\ngini = 0.444\\nsamples = 3\\nvalue = [0, 1, 2]'),\n",
              " Text(231.7846153846154, 54.359999999999985, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1, 0]'),\n",
              " Text(283.2923076923077, 54.359999999999985, 'gini = 0.0\\nsamples = 2\\nvalue = [0, 0, 2]'),\n",
              " Text(309.04615384615386, 90.6, 'gini = 0.0\\nsamples = 43\\nvalue = [0, 0, 43]')]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jK1Puhyn3Ldo",
        "outputId": "98c9a265-b9f1-4022-9ae6-4843406937c7"
      },
      "source": [
        "input_val = [X[15,:]]\n",
        "output_val = y[15]\n",
        "\n",
        "pre_tree = clf.predict(input_val)[0]\n",
        "\n",
        "print('Tree predicted class {pre_tree}, expected {output_val}')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tree predicted class {pre_tree}, expected {output_val}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stsnzJB74BZG",
        "outputId": "6f49c6fe-b538-4240-a62d-701efe4604ef"
      },
      "source": [
        "import numpy as np\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "x_shape = (X.shape[0] - 1, X.shape[1])\n",
        "\n",
        "# extract single element, becomes \"unknown\" element\n",
        "x = [X[5]]\n",
        "out = y[5]\n",
        "\n",
        "X = np.delete(X, 5, 0)\n",
        "y = np.delete(y, 5, 0)\n",
        "X = X.reshape(x_shape)\n",
        "\n",
        "# train the tree\n",
        "clf = tree.DecisionTreeClassifier()\n",
        "clf = clf.fit(X, y)\n",
        "\n",
        "# make the prediction\n",
        "clf.predict(x) # 0\n",
        "clf.predict_proba(x) # [1, 0, 0]\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmJzMSes2TLg"
      },
      "source": [
        "## Naive Bayes\n",
        "- probabilistic classifier under assumption that the attributes are conditionally independent\n",
        "$$\n",
        "P(X, c_i) = \\prod \\limits_{k=1}^n P(x_k|c_i) = P(x_1|c_i)\\times P(x_2|c_i)\\times \\ldots \\times P(x_n | c_i)\n",
        "$$\n",
        "- classification is conducted by deriving the max posterior, $\\max\\, P(c_i|X)$\n",
        "- simple algorithm to implement\n",
        "- good results in most cases\n",
        "- easy scalable to large datasets\n",
        "- can suffer from zero probability problem\n",
        "- needs to be fixed with laplacian estimator\n",
        "\n",
        "### Implementations\n",
        "\n",
        "There are multiple implementations available in `sklearn`.\n",
        "\n",
        "We'll start with **Gaussian Naive Bayes**.\n",
        "\n",
        "#### Gaussian Naive Bayes\n",
        "The likelihood of the features is assumed to be Gaussian\n",
        "\n",
        "$$\n",
        "P(x_i|y) = \\frac{1}{\\sqrt{2\\pi\\sigma_{y}^{2}}}\n",
        "\\text{exp}\n",
        "\\left(\n",
        "  -\\frac{(x_i-\\mu_y)^2}{2\\sigma_y^2}\\right)\n",
        "$$\n",
        "where we use the maximum likelihood to estimate $\\sigma_y$ and $\\mu_y$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SghYF5nb12nT"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "X, y = load_iris(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjPnLgnF63lT",
        "outputId": "38f27d45-254a-4dbb-fddc-168c2796889c"
      },
      "source": [
        "clf = GaussianNB()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "print(f'Number of mislabled points out of a total of {X_test.shape[0]} points: {(y_test != y_pred).sum()}')\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mislabled points out of a total of 75 points: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzxBEyI78r8I"
      },
      "source": [
        "#### Multinomial Naive Bayes (MNB)\n",
        "- naive Bayes for multinomially distributed data\n",
        "- used in text classification\n",
        "\n",
        "#### Complement Naive Bayes (CNB)\n",
        "- adaptation of MNB\n",
        "- suits for imbalanced datasets\n",
        "- used in text classification\n",
        "\n",
        "#### Bernoulli Naive Bayes\n",
        "- for multivariante Bernoulli distributed data\n",
        "- might have multiple features, but each needs to be binary\n",
        "- binary input\n",
        "- for text classification use word occurence vectors rather than word count vectors\n",
        "\n",
        "#### Categorical Naive Bayes\n",
        "- for categorial distributed data where each features has its own categorial distribution\n",
        "- assumes that all categories for all features are represented with numbers $0, \\ldots, n_i - 1$ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aboX2jxeDg3A"
      },
      "source": [
        "## Artificial Neural Networks\n",
        "A artificial neural network is a set of connected input/output units where each connection has a weight associated with it. During the learning phase, the network learns by adjusting the weights so as to be able to predict the correct class label of the input tuples.\n",
        "\n",
        "There are many network architectures like\n",
        "- Feed Forward NNs\n",
        "- Convolutional NNs\n",
        "- Recurrent NNs\n",
        "\n",
        "But the appropriate architecture depends on the application of the model. So again **no network that fits all needs**. But it's safe to claim that for most cases feed-forward models give reasonably accurate results and especially for tasks like image processing, convolutional networks perform better.\n",
        "\n",
        "Depending on the complexity of the function which is mapped to the model the model can or can not have multiple hidden layers. Having more hidden layers enables to model complex relationships such as deep neural networks.\n",
        "\n",
        "#### Pros:\n",
        "- perform impressively in most real world applications\n",
        "- high tolerance to noisy data\n",
        "- can classify untrained patterns\n",
        "- perform usually better with continuous-valued input and output\n",
        "\n",
        "#### Cons:\n",
        "- many hidden layers <=> long training time\n",
        "- poor interpretability of the model, compared to other models like Decision Trees, due to unknown symbolic meaning of learned weights\n",
        "\n",
        "### Code\n",
        "\n",
        "using `sklearn`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mZVM30qDo1n"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "\n",
        "X, y = load_iris(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=0)\n",
        "\n",
        "\n",
        "transformed_y_train = []\n",
        "for elem in y_train:\n",
        "  vec = [0,0,0]\n",
        "  vec[elem] = 1.0\n",
        "  transformed_y_train.append(vec)\n",
        "\n",
        "X_train = X_train\n",
        "y_train = transformed_y_train\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ws2nkG8Ffej",
        "outputId": "860a7e07-d4e6-46ca-d50b-5324bc64d7f8"
      },
      "source": [
        "clf = MLPClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "output = clf.predict([X_test[5, :]])\n",
        "\n",
        "print(f'Predicted: {output}, Expected: {y_test[5]}')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: [[0 0 1]], Expected: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeDWE_t3HLt-"
      },
      "source": [
        "#### `pytorch`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4R6zJyewHEz7"
      },
      "source": [
        "import torch\n",
        "torch_X_train = torch.tensor(X_train, dtype=float)\n",
        "torch_y_train = torch.tensor(y_train, dtype=float)\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IueKQcGwH84F"
      },
      "source": [
        "Single layer FNN.\n",
        "\n",
        "**One note:** We need to encode the three available classes \"Iris setosa, \"Iris virginica\" and \"Iris versicolor\" as three output parameters, to later on get the probability for each class and use simple $\\text{argmax}(y_0, y_1, y_2)$ as the final classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TarKazbtHSGY",
        "outputId": "b1268475-73a7-4b97-888f-1538832c6254"
      },
      "source": [
        "layer1 = torch.nn.Linear(X_train.shape[1], 3, dtype=float)\n",
        "\n",
        "layer1(torch.tensor(X_test[5], dtype=float))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-3.0272, -1.9356, -3.7428], dtype=torch.float64,\n",
              "       grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2OFrpNKIlKA"
      },
      "source": [
        "Adding an optimizer to train with"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uk1QSRkZINtK"
      },
      "source": [
        "optim = torch.optim.SGD(layer1.parameters(), lr=0.1)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "te4woGizLXVI"
      },
      "source": [
        "Trying to train the single layer model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqPw9i7sI2rO",
        "outputId": "8db567e2-6bd4-4687-fa23-9a01ade965f4"
      },
      "source": [
        "\n",
        "for i in range(50):\n",
        "  optim.zero_grad()\n",
        "\n",
        "  o = layer1(torch_X_train)\n",
        "  \n",
        "  error = torch.sum((o.view(-1) - torch_y_train.view(-1)) ** 2)\n",
        "  error.backward()\n",
        "  if i % 50 == 0:\n",
        "    print(error)\n",
        "  optim.step()\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2100.2360, dtype=torch.float64, grad_fn=<SumBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZlkSqIaJWay",
        "outputId": "6b5caa5f-867a-413a-bc59-3f8eab88f922"
      },
      "source": [
        "output = layer1(torch.tensor(X_test[5], dtype=float))\n",
        "\n",
        "print(output)\n",
        "print(f'Predicted: {tensor.argmax(output)}, Expected: {y_test[5]}')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: tensor([-1.3629e+149, -9.8585e+148, -1.5372e+149], dtype=torch.float64,\n",
            "       grad_fn=<AddBackward0>), Expected: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-_0UeLkLaqj"
      },
      "source": [
        "As we can see the result is rather poor. Let's add another layer to the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZDAH8PMJd1w",
        "outputId": "81feb857-05fe-4eb6-b055-a88172b380cb"
      },
      "source": [
        "layer1_out = 18\n",
        "layer2_out = 8\n",
        "final_out = 3\n",
        "\n",
        "layer1 = torch.nn.Linear(X_train.shape[1], layer1_out, dtype=float)\n",
        "layer2 = torch.nn.Linear(layer1_out, layer2_out, dtype=float)\n",
        "layer3 = torch.nn.Linear(layer2_out, final_out, dtype=float)\n",
        "layer3(layer2(layer1(torch.tensor(X_test[5], dtype=float))))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.7158, -1.8860, -0.2412], dtype=torch.float64,\n",
              "       grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyYiZBzUL5lk"
      },
      "source": [
        "optim = torch.optim.SGD([*layer1.parameters(), *layer2.parameters(), *layer3.parameters()], lr=0.01)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iluJb-cNLuLw",
        "outputId": "9247bbaf-dc59-44df-cbbe-25dd5b979366"
      },
      "source": [
        "for epoch in range(50):\n",
        "  for i in range(len(torch_y_train)):\n",
        "    optim.zero_grad()\n",
        "\n",
        "    output = layer3(layer2(layer1(torch_X_train[i])))\n",
        "\n",
        "    # output = torch.sigmoid(layer3(torch.sigmoid(layer2(torch.sigmoid(layer1(torch_X_train[i]))))))\n",
        "\n",
        "    error = torch.sum((output.view(-1) - torch_y_train[i]) ** 2)\n",
        "    error.backward()\n",
        "    if i % 50 == 0:\n",
        "      print(error)\n",
        "    optim.step()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.4120, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.1575, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0190, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0254, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0239, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0260, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0352, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0264, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0427, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0270, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0486, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0277, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0532, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0283, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0569, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0285, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0601, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0285, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0629, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0281, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0653, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0276, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0675, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0269, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0695, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0260, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0712, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0251, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0727, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0241, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0739, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0230, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0748, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0220, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0754, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0209, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0758, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0198, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0759, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0188, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0758, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0178, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0755, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0168, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0751, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0160, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0746, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0152, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0740, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0144, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0733, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0137, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0726, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0130, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0719, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0124, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0712, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0119, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0706, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0113, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0699, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0109, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0692, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0104, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0686, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0100, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0681, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0097, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0675, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0093, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0670, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0090, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0665, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0087, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0661, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0084, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0657, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0082, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0653, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0080, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0650, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0078, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0647, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0076, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0645, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0074, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0643, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0073, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0641, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0071, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0640, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0070, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0639, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0069, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0638, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0068, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0637, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0067, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0637, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0067, dtype=torch.float64, grad_fn=<SumBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPEVLFMhMIFf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bc0a4b8-66e4-461c-eaa3-ef35939639d8"
      },
      "source": [
        "prediction = torch.sigmoid(layer3(torch.sigmoid(layer2(torch.sigmoid(layer1(torch.tensor(X_test[5])))))))\n",
        "expected = y_test[5]\n",
        "\n",
        "print(prediction)\n",
        "print(f'Predicted: {torch.argmax(prediction)}, Expected: {expected}')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.4813, 0.6850, 0.6267], dtype=torch.float64,\n",
            "       grad_fn=<SigmoidBackward>)\n",
            "Predicted: 1, Expected: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YniHI7nOZAh3"
      },
      "source": [
        "As we can see neither of the manually created NNs using `pytorch` are giving satisfying results to our test data. Whereas the single layer NN gives bad to unuseful results, the multi layer NN has tendencies to reduce it's error, yet the fluctuation in said error is too unstable.\n",
        "\n",
        "One thing we could do is adding *activation* functions to each layer. For now all we do is\n",
        "$$\n",
        "L(X) = L_3(L_2(L_1(X)))\n",
        "$$\n",
        "which is actually equal to\n",
        "$$\n",
        "L(X) = P(X),\\\\\n",
        "\\text{where}\\, P = L_3 \\cdot L_2 \\cdot L_1\n",
        "$$\n",
        "As you can see instead of actually adjusting $\\beta$ values along the way, we  perform a single matrix-vector multiplication, which means under the hood we do in both cases the same thing.  \n",
        "So instead of doing all that fancy 3 layer stuff. Let's use two layers, and connect them with an activation function.\n",
        "\n",
        "Activation functions are a helpful tool to add complexity to the function the algorithm is learning. By adding complexity we can solve the problem of overfitting. But we will come back later in detail about these magic **activation functions**.\n",
        "\n",
        "For now we just see them as a tool to add complexity, which might improve the quality of predictions in our NN.\n",
        "\n",
        "One of these functions is sigmoid\n",
        "$$\n",
        "\\sigma(x) = \\frac{1}{1+\\exp(-x)}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "dsnPsKT8QzPU",
        "outputId": "e770707d-8483-4ba1-ebd7-814dc2894818"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "sigmoid = lambda x: 1.0/(1+np.exp(-x))\n",
        "\n",
        "x = np.linspace(-10, 10, 1000)\n",
        "\n",
        "plt.title('Sigmoid')\n",
        "plt.plot(x, sigmoid(x))\n",
        "plt.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feTZoIXFcR6S"
      },
      "source": [
        "This nifty function maps it's input into a range of $[0, 1]$.\n",
        "\n",
        "Applied to our NN:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nNcYZgiFGYj"
      },
      "source": [
        "layer1_out = 18\n",
        "layer2_out = 8\n",
        "final_out = 3\n",
        "\n",
        "layer1 = torch.nn.Linear(X_train.shape[1], layer1_out, dtype=float)\n",
        "layer2 = torch.nn.Linear(layer1_out, layer2_out, dtype=float)\n",
        "layer3 = torch.nn.Linear(layer2_out, final_out, dtype=float)\n",
        "layer3(layer2(layer1(torch.tensor(X_test[5], dtype=float))))\n",
        "optim = torch.optim.SGD([*layer1.parameters(), *layer2.parameters(), *layer3.parameters()], lr=0.1)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JeDuVwT6cdFf",
        "outputId": "af0c2680-f36d-42f4-f3d0-5f46f4b23cde"
      },
      "source": [
        "for epoch in range(50):\n",
        "  for i in range(len(torch_y_train)):\n",
        "    optim.zero_grad()\n",
        "\n",
        "    o1 = torch.sigmoid(layer1(torch_X_train[i]))\n",
        "    o2 = torch.sigmoid(layer2(o1))\n",
        "    output = torch.sigmoid(layer3(o2))\n",
        "\n",
        "    error = torch.sum((output.view(-1) - torch_y_train[i]) ** 2)\n",
        "    error.backward()\n",
        "    if i % 50 == 0:\n",
        "      print(error)\n",
        "    optim.step()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.6330, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.4743, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.6010, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.4735, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.5931, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.4697, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.5865, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.4651, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.5795, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.4584, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.5702, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.4476, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.5564, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.4289, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.5338, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.3955, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.4925, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.3373, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.4172, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.2541, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.3094, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.1685, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.2077, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.1076, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.1402, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0726, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.1009, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0533, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0786, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0426, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0658, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0364, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0585, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0328, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0544, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0308, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0523, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0297, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0515, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0293, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0515, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0292, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0519, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0293, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0526, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0296, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0535, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0299, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0544, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0302, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0553, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0305, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0562, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0308, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0571, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0311, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0578, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0312, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0582, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0311, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0583, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0310, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0579, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0306, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0570, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0301, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0557, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0295, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0540, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0288, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0520, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0280, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0497, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0271, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0471, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0260, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0444, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0249, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0416, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0236, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0387, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0223, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0359, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0210, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0332, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0197, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0307, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0184, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0283, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0172, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0261, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0160, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0241, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0150, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0223, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0140, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0206, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0132, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0191, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.0124, dtype=torch.float64, grad_fn=<SumBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3W3tAf9dNU2",
        "outputId": "dfb5d7a0-3027-463d-9325-041ebb6d5c42"
      },
      "source": [
        "prediction = torch.sigmoid(layer3(torch.sigmoid(layer2(torch.sigmoid(layer1(torch.tensor(X_test[5])))))))\n",
        "expected = y_test[5]\n",
        "\n",
        "print(f'Predicted: {torch.argmax(prediction)}, Expected: {expected}')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: 2, Expected: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUKixLRkdM9_"
      },
      "source": [
        "So as you can see adding this magical activation function helps to stabalize the prediction error and improve the quality of prediction by magnitudes.\n",
        "\n",
        "Alright, that covers the eager learners, since all of the above algorithms train a model in advance to generalize the training data und use these models to make predictions.\n",
        "\n",
        "## k-Nearest Neighbor (KNN)\n",
        "KNN is a lazy learning algorithm which stores all instances correspond to training data points in an $n$-dim space.  \n",
        "Calculates for unknown\n",
        "- discrete data the closest $k$ number of nearest neighbors\n",
        "- real-valued data the mean of $k$ nearest neighbors\n",
        "\n",
        "KNN is usually robust to noisy data, since it's averaging the $k$-nearest neighbors.\n",
        "\n",
        "### Code\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5effyFZdfEEv",
        "outputId": "432d7303-97e5-4b67-89c3-796d279a51cd"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn\n",
        "from matplotlib.colors import ListedColormap\n",
        "from sklearn import neighbors, datasets\n",
        "\n",
        "\n",
        "n_neighors = 10\n",
        "\n",
        "iris = datasets.load_iris()\n",
        "\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "uniform_clf = neighbors.KNeighborsClassifier(n_neighors, weights=\"uniform\")\n",
        "uniform_clf.fit(X_train, y_train)\n",
        "\n",
        "uniform_pred = uniform_clf.predict([X_test[5]])\n",
        "\n",
        "distance_clf = neighbors.KNeighborsClassifier(n_neighors, weights=\"distance\")\n",
        "distance_clf.fit(X_train, y_train)\n",
        "\n",
        "distance_pred = distance_clf.predict([X_test[5]])\n",
        "\n",
        "print(uniform_pred)\n",
        "print(distance_pred)\n",
        "print(y_test[5])\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 1.]]\n",
            "[[0. 0. 1.]]\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZfLKu_-oAcE"
      },
      "source": [
        "# Evaluation\n",
        "After training an algorithm it needs to be evaluated to verify its applicability.\n",
        "We've seen in previous sections things like Precision and Recall, but will now briefly verbalize some of the concepts of evaluation techniques.\n",
        "\n",
        "### Holdout method\n",
        "We split the data in the training set into 2 partitisions as test (20%) and train (80%). The train set is used to train the model and the test data set will be used to test its predictive power, as seen in the NN examples.\n",
        "\n",
        "### Cross-validation\n",
        "Overfitting is a common problem and can occure in most models. **k-fold cross-validation** can be conducted to verify over-fitting in a model. In this method the data will be randomly partitioned into $k$ mutually exclusive subsets, each approximately equal size and one is kept for testing while others are used for training. This process is iterated throught the whole $k$ folds.\n",
        "\n",
        "So in other words, we grab a fraction of the training set, use it for testing and then batch the remaining set into batches of the same size as our test set, then apply different batches while testing against the same test set.\n",
        "\n",
        "#### Cross-Valdation application\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqeUzK0d_IhA"
      },
      "source": [
        "# data preparation\n",
        "import random\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "batch_size = 5\n",
        "all_X, all_y = load_iris(return_X_y=True)\n",
        "\n",
        "foo = list(range(all_y.shape[0]))\n",
        "random.shuffle(foo)\n",
        "\n",
        "test_i = foo[:batch_size]\n",
        "X_test = all_X[test_i, :]\n",
        "y_test = all_y[test_i]\n",
        "\n",
        "X_train = all_X[foo[batch_size:], :]\n",
        "y_train = all_y[foo[batch_size:]]\n",
        "\n",
        "\n",
        "# transform y_train into N-dim vector containing probabilities for class N\n",
        "transformed_y_train = []\n",
        "for elem in y_train:\n",
        "  vec = [0,0,0]\n",
        "  vec[elem] = 1.0\n",
        "  transformed_y_train.append(vec)\n",
        "\n",
        "X_train = X_train\n",
        "y_train = transformed_y_train\n",
        "\n",
        "# build batches\n",
        "\n",
        "batches = []\n",
        "for b in range(int(len(y_train)/batch_size)):\n",
        "  batch = (X_train[batch_size * (b):batch_size * (b + 1), :], y_train[batch_size * (b):batch_size * (b + 1)])\n",
        "  batches.append(batch)\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSWk_zMgJRFD"
      },
      "source": [
        "Single Layer NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wH8FPdG8I904",
        "outputId": "b2f83304-37a4-499e-a100-a02d8788c396"
      },
      "source": [
        "layer1 = torch.nn.Linear(X_train.shape[1], 3, dtype=float)\n",
        "optim = torch.optim.SGD([*layer1.parameters()], lr=0.1)\n",
        "\n",
        "for epoch in range(50):\n",
        "  for batch in batches:\n",
        "    optim.zero_grad()\n",
        "    X = torch.tensor(batch[0])\n",
        "    y = torch.tensor(batch[1])\n",
        "\n",
        "    output = torch.sigmoid(layer1(X))\n",
        "\n",
        "    error = torch.sum((output - y) ** 2)\n",
        "    error.backward()\n",
        "    if epoch % 50 == 0:\n",
        "      print(error)\n",
        "    optim.step()"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(5.4943, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(2.7316, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(1.5703, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(3.3061, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(3.2600, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(4.2401, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(4.5638, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(4.1129, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(2.9317, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(2.7552, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(2.4544, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(4.6381, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(4.6648, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(2.1864, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(2.9323, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(2.5743, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(3.9635, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(2.7572, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(1.7966, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(3.9312, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(0.7975, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(1.2950, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(2.4074, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(3.0146, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(3.4998, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(6.1176, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(6.1180, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(4.0747, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(4.7811, dtype=torch.float64, grad_fn=<SumBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4lDjaplJH4g",
        "outputId": "588e906e-7e2d-4a3d-a51f-f1a74265df6a"
      },
      "source": [
        "prediction = torch.sigmoid(layer1(torch.tensor(X_test[-1])))\n",
        "expected = y_test[-1]\n",
        "print(prediction)\n",
        "\n",
        "print(f'Predicted: {prediction.argmax()}, Expected: {expected}')"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([9.5460e-01, 2.5805e-02, 1.8661e-08], dtype=torch.float64,\n",
            "       grad_fn=<SigmoidBackward>)\n",
            "Predicted: 0, Expected: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hlOOl9VJXL5"
      },
      "source": [
        "Multi-layer NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbPnn5ob-3vc",
        "outputId": "4e07f3d4-9490-40f2-9307-dcab6bb7e12c"
      },
      "source": [
        "layer1_out = 18\n",
        "layer2_out = 8\n",
        "final_out = 3\n",
        "\n",
        "layer1 = torch.nn.Linear(X_train.shape[1], layer1_out, dtype=float)\n",
        "layer2 = torch.nn.Linear(layer1_out, layer2_out, dtype=float)\n",
        "layer3 = torch.nn.Linear(layer2_out, final_out, dtype=float)\n",
        "layer3(layer2(layer1(torch.tensor(X_test[-1], dtype=float))))\n",
        "optim = torch.optim.SGD([*layer1.parameters(), *layer2.parameters(), *layer3.parameters()], lr=0.1)\n",
        "\n",
        "for epoch in range(50):\n",
        "  for batch in batches:\n",
        "    optim.zero_grad()\n",
        "    X = torch.tensor(batch[0])\n",
        "    y = torch.tensor(batch[1])\n",
        "\n",
        "    o1 = torch.sigmoid(layer1(X))\n",
        "    o2 = torch.sigmoid(layer2(o1))\n",
        "    output = torch.sigmoid(layer3(o2))\n",
        "\n",
        "    error = torch.sum((output - y) ** 2)\n",
        "    error.backward()\n",
        "    if epoch % 50 == 0:\n",
        "      print(error)\n",
        "    optim.step()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(3.5157, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(3.4490, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(3.1660, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(3.2583, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(3.2894, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(3.7224, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(3.5022, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(3.3989, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(3.3374, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(3.4981, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(3.4187, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(3.3795, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(3.2440, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(3.7034, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(3.3137, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(3.5064, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(3.2872, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(3.3377, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(3.4969, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(3.5075, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(3.4674, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(3.3958, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(3.2738, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(3.5705, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(3.7423, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(3.3966, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(3.5110, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(3.5155, dtype=torch.float64, grad_fn=<SumBackward0>)\n",
            "tensor(3.4372, dtype=torch.float64, grad_fn=<SumBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Kd2eVNyDOY_",
        "outputId": "a62f9b27-ae5f-43b4-b6b9-8f60678f16a8"
      },
      "source": [
        "prediction = torch.sigmoid(layer3(torch.sigmoid(layer2(torch.sigmoid(layer1(torch.tensor(X_test[-1])))))))\n",
        "expected = y_test[-1]\n",
        "print(prediction)\n",
        "\n",
        "print(f'Predicted: {prediction.argmax()}, Expected: {expected}')"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([9.4492e-01, 6.2796e-02, 4.4966e-04], dtype=torch.float64,\n",
            "       grad_fn=<SigmoidBackward>)\n",
            "Predicted: 0, Expected: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hbWRAZND6_4"
      },
      "source": [
        "As you can see using **cross-validation** can even improve results from NNs. Whereas the regular holdout approach required a few iterations over the full training set to perform comparable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kkt_H5wV-4dO"
      },
      "source": [
        "\n",
        "\n",
        "## [Precision and Recall](/Machine_Learning/Precision_Recall.ipynb)\n"
      ]
    }
  ]
}